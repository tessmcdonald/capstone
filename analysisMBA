// import RFM data

cd /home
mkdir segments
cd /home/segments

hadoop fs -mkdir /user/segments/
hadoop fs -put segments.csv /user/segments/

create table capstone.segments (
segment INT
id STRING)
ROW FORMAT DELIMITED
FIELDS TERMINATED BY ',';

load data inpath '/user/segments/segments.csv'
into table capstone.segments;



create table dataMBA as
select a.id, a.transdate, a.category, a.brand, b.segment
from cleandatax a join segments b
on a.id = b.id; 

create table segmentONE as
select id, transdate, category, brand, segment,
concat(category, brand) as product,
concat(id, transdate) as transID
from dataMBA
where segment = 1;

create table segmentTWO as
select id, transdate, category, brand, segment,
concat(category, brand) as product,
concat(id, transdate) as transID
from dataMBA
where segment = 2;

create table segmentTHREE as
select id, transdate, category, brand, segment,
concat(category, brand) as product,
concat(id, transdate) as transID
from dataMBA
where segment = 3;

create table segmentFOUR as
select id, transdate, category, brand, segment,
concat(category, brand) as product,
concat(id, transdate) as transID
from dataMBA
where segment = 4;







setwd('\\\\files.loyalty.com/users/tmcdonald/My Documents/Big Data & Predictive Analytics')
segmentTEST <- read.csv('part1.csv', sep = ',', header = FALSE)


select product, count(*) as total
from segmentONE
group by product
order by total desc
limit 25;

select product, count(distinct transID) as total from segmentone
group by product
order by total desc
limit 25; 

select count(distinct transID) from segmenttwo; 

