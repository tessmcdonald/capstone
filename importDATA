/////import CSV file into HADOOP DISTRIBUTED FILE SYSTEM



// list files in the current directory
ll

// show the current directory path
pwd

// enter the 'home' directory
cd /home

// create a directory called 'transactions'
mkdir transactions



// show folders in HDFS 'user' directory
hadoop fs -ls /user/

// create a new directory called 'transactions'
hadoop fs -mkdir /user/transactions/

// put 'transactions_1' file in transactions directory
hadoop fs -put transactions_1.csv /user/transactions/

// put 'transactions_2' file in transactions directory
hadoop fs -put transactions_2.csv /user/transactions/

// put 'transactions_3' file in transactions directory
hadoop fs -put transactions_3.csv /user/transactions/

// put 'transactions_4' file in transactions directory
hadoop fs -put transactions_4.csv /user/transactions/

// put 'transactions_5' file in transactions directory
hadoop fs -put transactions_5.csv /user/transactions/

// show files in HDFS 'transactions' directory
hadoop fs -ls /user/transactions/





///// import data into HIVE (create DATABASE & TABLES)



create database capstone;

use capstone;



// create 'transactions' table
create table capstone.transactions (
      id STRING,
      chain INT,
      dept STRING,
      category STRING,
      company STRING,
      brand STRING,
      transdate DATE,
      productsize DOUBLE,
      productmeasure STRING,
      purchasequantity DOUBLE,
      purchaseamount DOUBLE)
ROW FORMAT DELIMITED
FIELDS TERMINATED BY ','
TBLPROPERTIES("SKIP.HEADER.LINE.COUNT"="1");

LOAD DATA INPATH '/user/transactions/transactions_1.csv'
INTO TABLE capstone.transactions;

LOAD DATA INPATH '/user/transactions/transactions_2.csv'
INTO TABLE capstone.transactions;

LOAD DATA INPATH '/user/transactions/transactions_3.csv'
INTO TABLE capstone.transactions;

LOAD DATA INPATH '/user/transactions/transactions_4.csv'
INTO TABLE capstone.transactions;

LOAD DATA INPATH '/user/transactions/transactions_5.csv'
INTO TABLE capstone.transactions;



