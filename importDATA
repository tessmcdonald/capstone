/////import CSV files into HADOOP DISTRIBUTED FILE SYSTEM



// list files in the current directory
ll

// show the current directory path
pwd

// enter the 'home' directory
cd /home

// create a directory called 'offers'
mkdir offers

// create a directory called 'history'
mkdir history

// create a directory called 'transactions'
mkdir transactions





// show folders in HDFS 'user' directory
hadoop fs -ls /user/

// create a new directory called 'offers'
hadoop fs -mkdir /user/offers/

// put 'offers' file in offers directory
hadoop fs -put offers.csv /user/offers/

// create a new directory called 'history'
hadoop fs -mkdir /user/history/

// put 'history' file in offers directory
hadoop fs -put trainHistory.csv /user/history/

// create a new directory called 'transactions'
hadoop fs -mkdir /user/transactions/

// put 'transactions' file in offers directory
hadoop fs -put transactions.csv /user/transactions/

// show files in HDFS 'offers' directory
hadoop fs -ls /user/offers/







///// import data into HIVE (create DATABASE & TABLES)



create database capstone;

use capstone;


// create 'transactions' table
create external table capstone.transactions (
      id STRING,
      chain STRING,
      dept STRING,
      category STRING,
      company STRING,
      brand STRING,
      transdate DATE,
      productsize DOUBLE,
      productmeasure STRING,
      purchasequantity DOUBLE,
      purchaseamount DOUBLE)
ROW FORMAT DELIMITED
FIELDS TERMINATED BY ','
LINES TERMINATED BY '\n'
LOCATION '/user/capstone/';

// create 'offers' table
create external table capstone.offers (
      offer STRING,
      category STRING,
      quantity DOUBLE,
      company STRING,
      offervalue DOUBLE,
      brand STRING)
ROW FORMAT DELIMITED
FIELDS TERMINATED BY ','
LINES TERMINATED BY '\n'
LOCATION '/user/capstone/';
