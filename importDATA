/////import CSV files into HADOOP DISTRIBUTED FILE SYSTEM



// list files in the current directory
ll

// show the current directory path
pwd

// enter the 'home' directory
cd /home

// create a directory called 'capstone'
mkdir capstone

// enter the 'capstone' directory
cd capstone



// show folders in HDFS 'user' directory
hadoop fs -ls /user/

// create a new directory called 'capstone'
hadoop fs -mkdir /user/capstone/

// show files in HDFS 'capstone' directory
hadoop fs -ls /user/capstone/

// put 'transaction' file in capstone directory
hadoop fs -put transactions.csv /user/capstone/





///// import data into HIVE (create DATABASE & TABLES)



create database capstone;

use capstone;


// create 'transactions' table
create external table capstone.transactions (
      id STRING,
      chain STRING,
      dept STRING,
      category STRING,
      company STRING,
      brand STRING,
      transdate DATE,
      productsize DOUBLE,
      productmeasure STRING,
      purchasequantity DOUBLE,
      purchaseamount DOUBLE)
ROW FORMAT DELIMITED
FIELDS TERMINATED BY ','
LINES TERMINATED BY '\n'
LOCATION '/user/capstone/';
